# MSc-Dissertation-Variational-Inference

Variational inference methods have attracted a lot of attention in Bayesian statistics
as they have empirically been shown to be widely applicable to high-dimensional machinelearning problems. Yet, the empirical performances of Variational Inference methods are
often impacted by two factors: one, an inappropriate choice of the objective function appearing in the optimisation problem and two, a search space that is too restrictive to match
the target at the end of the optimisation procedure.
The goal of this project is to explore how one can remedy the two issues mentioned above
by (i) selecting the alpha-divergence as a more general class of objective functions and (ii)
enlarging the search space beyond the traditional framework used in Variational Inference.
The line of research developed in will serve as the basis for this project, with a
focus on understanding whether the methods introduced in these papers can be used to
outperform state-of-the-art algorithms
